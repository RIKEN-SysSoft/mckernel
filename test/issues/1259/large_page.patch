diff --git arch/arm64/kernel/memory.c arch/arm64/kernel/memory.c
index e776818..4e57dc1 100644
--- arch/arm64/kernel/memory.c
+++ arch/arm64/kernel/memory.c
@@ -2690,6 +2690,13 @@ int set_range_l1(void *args0, pte_t *ptep, uintptr_t base, uintptr_t start,
 	ptl1_set(ptep, pte);
 
 	error = 0;
+
+	if (args->attr[0] & PTE_CONT &&
+	    __page_offset(base, PTL1_CONT_SIZE) == 0) {
+		kprintf("%s: large page allocation, addr: %016lx, size: 0x%lx, phys: %lx\n",
+			__func__, base, PTL1_CONT_SIZE, phys);
+	}
+
 	// call memory_stat_rss_add() here because pgshift is resolved here
 	if (rusage_memory_stat_add(args->range, phys, PTL1_SIZE, PTL1_SIZE)) {
 		dkprintf("%lx+,%s: calling memory_stat_rss_add(),base=%lx,phys=%lx,size=%ld,pgsize=%ld\n",
@@ -2782,6 +2789,17 @@ retry:
 				ptl_set(ptep, phys | args->attr[level-1],
 					level);
 				error = 0;
+
+				if (args->attr[level-1] & PTE_CONT) {
+					if (__page_offset(base, tbl.cont_pgsize) == 0) {
+						kprintf("%s: large page allocation, addr: %016lx, size: 0x%lx, phys: %lx\n",
+							__func__, base, tbl.cont_pgsize, phys);
+					}
+				} else {
+					kprintf("%s: large page allocation, addr: %016lx, size: 0x%lx, phys: %lx\n",
+						__func__, base, tbl.pgsize, phys);
+				}
+
 				dkprintf("set_range_middle(%lx,%lx,%lx,%d):"
 					 "large page. %d %lx\n",
 					 base, start, end, level, error, *ptep);
diff --git arch/x86_64/kernel/memory.c arch/x86_64/kernel/memory.c
index df545e1..c8c92b5 100644
--- arch/x86_64/kernel/memory.c
+++ arch/x86_64/kernel/memory.c
@@ -1931,6 +1931,10 @@ retry:
 			dkprintf("set_range_l2(%lx,%lx,%lx):"
 					"2MiB page. %d %lx\n",
 					base, start, end, error, *ptep);
+
+			kprintf("%s: large page allocation, addr: %016lx, size: 0x%lx\n",
+				__func__, base, PTL2_SIZE);
+
 			// Call memory_stat_rss_add() here because pgshift is resolved here
 			if (rusage_memory_stat_add(args->range, phys, PTL2_SIZE, PTL2_SIZE)) {
 				dkprintf("%lx+,%s: calling memory_stat_rss_add(),base=%lx,phys=%lx,size=%ld,pgsize=%ld\n", phys, __FUNCTION__, base, phys, PTL2_SIZE, PTL2_SIZE);
@@ -2020,6 +2024,9 @@ retry:
 					"1GiB page. %d %lx\n",
 					base, start, end, error, *ptep);
 
+			kprintf("%s: large page allocation, addr: %016lx, size: 0x%lx\n",
+				__func__, base, PTL3_SIZE);
+
 			// Call memory_stat_rss_add() here because pgshift is resolved here
 			if (rusage_memory_stat_add(args->range, phys, PTL3_SIZE, PTL3_SIZE)) {
 				dkprintf("%lx+,%s: calling memory_stat_rss_add(),base=%lx,phys=%lx,size=%ld,pgsize=%ld\n", phys, __FUNCTION__, base, phys, PTL3_SIZE, PTL3_SIZE);
diff --git kernel/include/rusage_private.h kernel/include/rusage_private.h
index 6cc9791..1f06cd4 100644
--- kernel/include/rusage_private.h
+++ kernel/include/rusage_private.h
@@ -12,7 +12,7 @@
 #include <ihk/debug.h>
 #include <memory.h>
 
-#ifdef ENABLE_RUSAGE
+#if 0 /* def ENABLE_RUSAGE */
 
 #define RUSAGE_OOM_MARGIN (2 * 1024 * 1024) // 2MB
 
diff --git kernel/process.c kernel/process.c
index b63dba6..9e575b6 100644
--- kernel/process.c
+++ kernel/process.c
@@ -2056,6 +2056,12 @@ retry:
 		}
 
 		dkprintf("%s: attr=%x\n", __FUNCTION__, attr);
+
+		if (pgsize > PAGE_SIZE) {
+			kprintf("large page allocation, addr: %016lx, size: %d, phys: %lx\n",
+				pgaddr, pgsize, phys);
+		}
+
 		error = ihk_mc_pt_set_pte(vm->address_space->page_table, ptep,
 		                          pgsize, phys, attr);
 		if (error) {
diff --git kernel/xpmem.c kernel/xpmem.c
index 5ac902b..9412626 100644
--- kernel/xpmem.c
+++ kernel/xpmem.c
@@ -1870,6 +1870,7 @@ int xpmem_fault_process_memory_range(
 	}
 
 	pte = xpmem_vaddr_to_pte(seg_tg->vm, seg_vaddr, &pgsize);
+	kprintf("XPMEM_PAGE_FAULT: vaddr: 0x%lx  pgsize: 0x%lx\n", vaddr, pgsize);
 
 	att->flags |= XPMEM_FLAG_VALIDPTEs;
 
